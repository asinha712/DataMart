source_list:
#  - SB
#  - OL
  - 1CP
#  - CUST_ADDR

target_list:
  - REGIS_DIM

SB:
  mysql_conf:
    dbtable: testdb.TRANSACTIONSYNC
    partition_column: App_Transaction_Id
    query: "(select * from testdb.TRANSACTIONSYNC where Internal_Member_Id = 'PC7135361') as t"

OL:
  sftp_conf:
    filetype: csv
    delimiter: |
    directory: /home/ubuntu/data
    filename: receipts_delta_GBR_14_10_2017.csv

1CP:
  s3_conf:
    s3_bucket: asinha
    filename: KC_Extract_1_20171009.csv

CUST_ADDR:
  mongodb_config:
    database: cust
    collection: cust

REGIS_DIM:
  target_table: DATAMART.REGIS_DIM
  source_data: 1CP
  loading_query: >
    SELECT
       DATAMART.FN_UUID() AS REGIS_KEY, REGIS_CNSM_ID AS CNSM_ID,REGIS_CTY_CODE AS CTY_CODE,
       REGIS_ID, REGIS_DATE, REGIS_LTY_ID AS LTY_ID, REGIS_CHANNEL, REGIS_GENDER, REGIS_CITY, INS_TS
      FROM
        (SELECT
           DISTINCT REGIS_CNSM_ID, CAST(REGIS_CTY_CODE AS SMALLINT), CAST(REGIS_ID AS INTEGER),
           REGIS_LTY_ID, REGIS_DATE, REGIS_CHANNEL, REGIS_GENDER, REGIS_CITY, INS_TS
        FROM
          staging_STG_1CP
        WHERE
          CAST(INS_TS AS DATE) = CURRENT_DATE
        ) CP


s3_conf:
  s3_bucket: asinha
  staging_area: staging_pg


redshift_conf:
  filetype: csv
  delimiter: |
  dbtable: PUBLIC.TXN_FCT
  query: SELECT txn_id, create_time, amount, cust_id from PUBLIC.TXN_FCT

spark_sql_demo:
  agg_demo: >
    select
        AccountNumber,
        UniqueTransactionDescriptions,
        sort_array(UniqueTransactionDescriptions, false) as OrderedUniqueTransactionDescriptions,
        size(UniqueTransactionDescriptions) as CountOfUniqueTransactionTypes,
        array_contains(UniqueTransactionDescriptions, 'Movies') as WentToMovies
    from
        agg_finances


  case_when_demo: >
    select
        company,
        employee.firstName as firstName,
        case
            when company = 'FamilyCo' then 'Premium'
            when company = 'OldCo' then 'Legacy'
            else 'Standard'
        end as Tier
    from
        employees
